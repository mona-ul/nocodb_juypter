{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f528b2a-4a8c-43f4-a2a8-12baa0b601ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nocodb_base import fetch_all_rows_from_nocodb, update_row\n",
    "from file_utils import write_json, write_tsv, read_tsv\n",
    "import re\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4d62bc-b6c2-4c6f-a767-297335f7958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "xc_token = \"\"\n",
    "# all cloudfront urls\n",
    "#table_id = \"mxp572bg586eppw\"\n",
    "#view_id = \"vwy8ovu97qes5d9h\"\n",
    "# all pages\n",
    "table_id = \"mipbzus6tit41os\"\n",
    "view_id = \"vw0tbcsv7njdrdel\"\n",
    "\n",
    "merge_table_id = \"ml5fr69pkq9zeri\"\n",
    "merge_view_id = \"vwn8jjpocrzon8oc\"\n",
    "\n",
    "noco_base_url = \"\"\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'xc-token': xc_token,\n",
    "}\n",
    "seed_file = \"add_url_lists/xml_export/urls_venues.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe6261-41b5-4a5a-a9b4-f7cf526d313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_data = fetch_all_rows_from_nocodb(noco_base_url, headers, table_id, view_id)\n",
    "merge_rows_data = fetch_all_rows_from_nocodb(noco_base_url, headers, merge_table_id, merge_view_id)\n",
    "#print(rows_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b57ec-59df-4e98-9f54-e157b9681854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_utils import write_json, write_tsv\n",
    "output_file = \"aqnb_url_list.txt\"\n",
    "write_tsv(output_file, rows_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d49d8-2a5c-4904-ac5c-f52c4e9e0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_data = read_tsv(\"aqnb_url_list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c35628-3302-4033-bb4c-d07a2a1b4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, urlunparse, quote\n",
    "\n",
    "def normalize_url(url):\n",
    "    url = url.strip()\n",
    "    parsed = urlparse(url)\n",
    "\n",
    "    scheme = parsed.scheme.lower()\n",
    "    netloc = parsed.netloc.lower()\n",
    "\n",
    "    # Lowercase path, strip trailing slash\n",
    "    path = parsed.path.rstrip('/').lower()\n",
    "\n",
    "    # Keep query string if present (as-is)\n",
    "    query = parsed.query\n",
    "\n",
    "    # Rebuild the normalized URL\n",
    "    normalized = urlunparse((scheme, netloc, path, '', query, ''))\n",
    "\n",
    "    # Encode safely (optional but helpful if comparing to encoded index)\n",
    "    return quote(normalized, safe=':/?&=%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a9eaa-de24-474b-b290-e10ec74bdc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_row_defined_data(noco_base_url, headers, table_id, record_id, update_data):\n",
    "    \"\"\"Update the index_check column in NocoDB.\"\"\"\n",
    "    request_url = (\n",
    "        f\"{noco_base_url}/api/v2/tables/{table_id}/records\"\n",
    "    )\n",
    "    try:\n",
    "        response = requests.patch(request_url, headers=headers, json=update_data)\n",
    "        if response.status_code == 200:\n",
    "            pass\n",
    "            #print(f\"Updated record {record_id} -> index_check: {index_status}\")\n",
    "        else:\n",
    "            print(f\"Failed to update record {record_id}. Status: {response.status_code}\")\n",
    "            print(f\"Response text: {response.text}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error updating record {record_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057188bd-ad6e-457a-b8c0-33132e1723a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_row_defined_data(noco_base_url, headers, table_id, update_data):\n",
    "    request_url = (\n",
    "            f\"{noco_base_url}/api/v2/tables/{table_id}/records\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(request_url, headers=headers, json=update_data)\n",
    "        if response.status_code == 200:\n",
    "            pass\n",
    "            #print(f\"created record -> new value\")\n",
    "        else:\n",
    "            print(f\"Failed to create. Status: {response.status_code}\")\n",
    "            log_lines.append(f\"failed: {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error creating record: {e}\") \n",
    "        log_lines.append(f\"Error: {e}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e926ba3-0bf2-416c-8dcb-35b2a32f96fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_multiselect_field(existing, new):\n",
    "    # Handle both strings and lists gracefully\n",
    "    def to_set(val):\n",
    "        if isinstance(val, list):\n",
    "            return set(val)\n",
    "        elif isinstance(val, str):\n",
    "            return set(item.strip() for item in val.split(',') if item.strip())\n",
    "        else:\n",
    "            return set()\n",
    "\n",
    "    current_items = to_set(existing)\n",
    "    new_items = to_set(new)\n",
    "    \n",
    "    combined_items = sorted(current_items.union(new_items))\n",
    "    return combined_items  # ✅ return as list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e78cc-008a-4fa7-a0f5-ad33c76c21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_url_lookup = {}\n",
    "for row in merge_rows_data:\n",
    "    normalized = normalize_url(row.get(\"URL\"))  # or use \"normalized_url\" if it's already normalized in table\n",
    "    merge_url_lookup[normalized] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d533151-b1aa-4756-94c0-53dffacbb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "merged_rows = {}\n",
    "\n",
    "# Open log file at the top so we can write and flush progressively\n",
    "with open(\"merge_log.txt\", \"w\", encoding=\"utf-8\") as log_file:\n",
    "\n",
    "    # First, load existing rows from merge table\n",
    "    for row in merge_rows_data:\n",
    "        url = row.get(\"URL\")\n",
    "        if url:\n",
    "            normalized = normalize_url(url)\n",
    "            merged_rows[normalized] = row.copy()\n",
    "\n",
    "    # Now, merge data from input table\n",
    "    for row in rows_data:\n",
    "        input_url = row.get(\"URL\")\n",
    "        if not input_url:\n",
    "            continue\n",
    "\n",
    "        normalized = normalize_url(input_url)\n",
    "        identified_via_new = row.get(\"Identified_via\") or \"\"\n",
    "        type_value_new = row.get(\"type\") or \"\"\n",
    "\n",
    "        # Safe string logging\n",
    "        log_file.write(f\"----------------------------- item\\n\")\n",
    "        log_file.write(f\"URL: {normalized}\\n\")\n",
    "        log_file.write(f\"identified_via_new: {identified_via_new}\\n\")\n",
    "        log_file.write(f\"type_value_new: {type_value_new}\\n\")\n",
    "        log_file.flush()\n",
    "\n",
    "        if normalized in merged_rows:\n",
    "            merged = merged_rows[normalized]\n",
    "            type_existing = merged.get(\"type\", \"\")\n",
    "            identified_via_existing = merged.get(\"Identified_via\", \"\")\n",
    "\n",
    "            log_file.write(f\"----------- existing data\\n\")\n",
    "            log_file.write(f\"type_existing: {type_existing}\\n\")\n",
    "            log_file.write(f\"identified_via_existing: {identified_via_existing}\\n\")\n",
    "            log_file.flush()\n",
    "\n",
    "            identified_via_combined = merge_multiselect_field(identified_via_existing, identified_via_new)\n",
    "            type_combined = merge_multiselect_field(type_existing, type_value_new)\n",
    "\n",
    "            merged[\"Identified_via\"] = identified_via_combined\n",
    "            merged[\"type\"] = type_combined\n",
    "\n",
    "            log_file.write(f\"----------- merged data\\n\")\n",
    "            log_file.write(f\"identified_via_combined: {', '.join(identified_via_combined)}\\n\")\n",
    "            log_file.write(f\"type_combined: {', '.join(type_combined)}\\n\")\n",
    "            log_file.flush()\n",
    "\n",
    "        else:\n",
    "            # New entry\n",
    "            merged_rows[normalized] = {\n",
    "                \"URL\": normalized,\n",
    "                \"Identified_via\": identified_via_new,\n",
    "                \"type\": type_value_new,\n",
    "            }\n",
    "\n",
    "    # Upload merged rows\n",
    "    for row in merged_rows.values():\n",
    "        log_file.write(f\"----------- uploading: {row['URL']}\\n\")\n",
    "        log_file.flush()\n",
    "\n",
    "        create_row_defined_data(noco_base_url, headers, merge_table_id, row)\n",
    "\n",
    "print(\"✅ Log written and data uploaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dffc52-fa4e-4e6d-a8d7-0c94b5777a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc1032-60b2-4e34-98a7-a560ca1a6cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
